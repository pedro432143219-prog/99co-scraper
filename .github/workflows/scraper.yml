name: Scraper Bali Auto

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install dependencies
        run: npm install
      
      - name: Install Playwright browsers
        run: npx playwright install chromium # Ajout√© pour Playwright
      
      - name: Run scraper
        run: node scraper.js
      
      - name: Show results
        if: always()
        run: |
          echo "=== R√âSULTATS ==="
          if [ -f resultats.csv ]; then
            echo "‚úÖ CSV cr√©√©"
            wc -l resultats.csv
            echo ""
            head -n 10 resultats.csv
          else
            echo "‚ùå Pas de CSV"
          fi
          
          if [ -f debug.html ]; then
            echo ""
            echo "üìÑ debug.html: $(wc -c < debug.html) octets"
          fi
      
      - name: Upload debug
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: debug-html
          path: debug.html
          retention-days: 1
      
      - name: Commit CSV
        uses: stefanzweifel/git-auto-commit-action@v5 # Remplacement de l'√©tape manuelle
        if: success()
        with:
          commit_message: "Update $(date -u +'%Y-%m-%d %H:%M')"
          file_pattern: 'resultats.csv'
          # Le GITHUB_TOKEN est utilis√© automatiquement par cette action
      
      - name: Upload CSV
        uses: actions/upload-artifact@v4
        if: success()
        with:
          name: resultats
          path: resultats.csv
          retention-days: 7
